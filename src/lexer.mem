LazyObject = import 'lazy-object.js'

rx = clone LazyObject: ({
  IDENTIFIER = /^([a-zA-Z_$][0-9a-zA-Z_\-]*)/
  NUM = /^((\d+\.)?\d+)+/
  STR = /^'(.*?)'/
  LAMBDA = /^([-|*]>)/
  OPERATION = /^(<\+|<=|>=|>|<|=>|(!|=)==?|\|\||\&\&|!!|\+\+|\+:)+/
  TERMINATOR = /^\n/
  REGEX = /^(\/((?![\s=])[^[\/\n\\]*(?:(?:\\[\s\S]|\[[^\]\n\\]*(?:\\[\s\S][^\]\n\\]*)*])[^[\/\n\\]*)*)\/)([imgy]{0,4})(?!\w)/
  COMMENTS = /^(#.*)/
  WHITESPACE = /^ /
})

identifiers = clone LazyObject: ({
  KEYWORDS = ['if', 'then', 'else', 'import', 'export', 'try', 'catch', 'none',
    'raise', 'object', 'clones', 'clone', 'prototype', 'recur']
  TYPE = ['Function', 'Number', 'String', 'Array', 'Object', 'Null']
  COMPARE = ['==', '!=', '>', '>=', '<', '<=', 'is', 'isnt']
  LEFT_OPERATORS = ['++', '!!', '<+']
  RIGHT_OPERATORS = ['=>', '+:']
  NOT = ['not']
  LOGIC = ['and', 'or', '&&', '||']
  BOOL = ['true', 'false']
})

ignore = ({ 'COMMENTS', 'WHITESPACE' })

get-type = \a -> rx |
  (.filter: (\x -> rx !! x | (.test: a))) |
  (.head: none)

extract = \key, chunk -> rx !! key | (.exec: chunk)

parse-alphanumeric = \t, chunk -> extract: t, chunk | (!! 1)

return-identifier = \type, item ->
  'KEYWORDS' ? [(item.toUpperCase!), item]
  else ? [type, item]

parse-identifier = \t, chunk -> {
  item = extract: t, chunk
  token = identifiers |
    (.filter: (\x -> identifiers !! x | (.indexOf: item.2) | (>= 0))) |
    (.head: none)
  return-identifier: token || t, item.2
}

parse-regular-expressions = \t, chunk -> {
  item = extract: t, chunk
  regexp = clone RegExp: item.3, item.4
  ['REGEXP', regexp]
}

get-token = \t, chunk, n ->
  'IDENTIFIER' ? parse-identifier: t, chunk
  'NUM' ? parse-alphanumeric: t, chunk
  'STR' ? parse-alphanumeric: t, chunk
  'OPERATION' ? parse-identifier: t, chunk
  'LAMBDA' ? parse-alphanumeric: t, chunk
  'REGEX' ? parse-regular-expressions: t, chunk
  'COMMENTS' ? parse-alphanumeric: t, chunk
  'WHITESPACE' ? ' '
  'TERMINATOR' ? ' '
  else ? [chunk.1, chunk.1]

process-chunk = \code, n -> {
  type = get-type: code
  token = get-token: type, code, n
  if Array.isArray: token
    then {
      token.push: n.line
      token
    }
    else [type, token, n.line]
}

get-length = \token, i ->
  'STR' ? i + 2
  else ? i

incr-line = \type, line ->
  'TERMINATOR' ? line + 1
  else ? line

return-tokens = \tokens, code, n ->
  not code ? tokens
  else ? {
    token = process-chunk: code, n
    index = token.2.toString! | (.length) | get-length: token.1
    tokens.push: token
    return-tokens: tokens, (code.substr: index, code.length),
      ({ line = (incr-line: token.1, n.line) })
  }

filter-whitespace = \token -> not (ignore !! token.1)

export tokenize = \code -> return-tokens: [], code, ({ index = 0, line = 0 }) |
  (.filter: filter-whitespace)
