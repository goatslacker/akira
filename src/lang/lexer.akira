rx = {
  @IDENTIFIER /^([a-zA-Z_$][0-9a-zA-Z_\-]*[\?]?)/
  @KEY /^(@[a-zA-Z_$][0-9a-zA-Z_\-]*[\?]?)/
  @NUM /^(-?([0-9]+[\.e])?[0-9]+,?)+/
  @STR /^('(.*?)')/
  @ARGS /^(&([0-9]+))/
  @LAMBDA /^->/
  @OPERATION /^(<<|<=|>=|>|<|(!|=)==?|\|\||\&\&|!!|\+\+|\+:|::)/
  @TERMINATOR /^\n/
  @REGEXP /^(\/((?![\s=])[^[\/\n\\]*(?:(?:\\[\s\S]|\[[^\]\n\\]*(?:\\[\s\S][^\]\n\\]*)*])[^[\/\n\\]*)*)\/)([imgy]{0,4})(?!\w)/
  @COMMENTS /^(--.*)/
  @WHITESPACE /^ /
}

identifiers = {
  @KEYWORDS ['if' 'then' 'else' 'import' 'export' 'try' 'catch' 'none' 'do'
    'let' 'fn' 'raise' 'prototype' 'recur' 'macro' 'cond' 'match' 'interface'
    'Maybe' 'Async' 'class' 'typealias' 'async' 'new' 'await']
  @COMPARE ['==' '!=' '>' '>=' '<' '<=' 'is' 'isnt']
  @INHERITANCE ['<<']
  @ACCESSOR_OPERATOR ['!!']
  @LEFT_OPERATORS ['++']
  @RIGHT_OPERATORS ['+:']
  @TYPE_OPERATOR ['::']
  @NOT ['not']
  @LOGIC ['&&' '||']
  @BOOL ['true' 'false']
}

ignore = { @COMMENTS @WHITESPACE }

get-type = fn [a] {
  rx | find (-> &0.test a)
}

extract = fn [key chunk] {
  rx !! key | (.exec chunk)
}

parse-alphanumeric = fn [t chunk (n = 1)] {
  extract t chunk | (!! n)
}

return-identifier = match {
  ['KEYWORDS' item] [(item.toUpperCase!) item item]
  [type item] [type item item]
}

parse-identifier = fn [t chunk] {
  item = extract t chunk
  token = identifiers | find (-> &0.indexOf item.1 | (>= 0))
  return-identifier (token || t) item.1
}

convert-regexp = fn [item] {
  RegExp item.2 item.3
}

parse-regular-expressions = fn [] {
  extract &! | convert-regexp | (-> ['REGEXP' &0 &0])
}

parse-args = fn [type chunk] {
  token = extract type chunk | (!! 2)
  raw = extract type chunk | (!! 0)
  [type token raw]
}

parse-str = fn [type chunk] {
  token = extract type chunk | (!! 2)
  raw = extract type chunk | (!! 0)
  [type token raw]
}

get-token = fn [type chunk]
  cond
    type is 'IDENTIFIER' ||
    type is 'KEY' ||
    type is 'OPERATION' ? parse-identifier &!
    type is 'NUM' ? parse-alphanumeric type chunk 0
    type is 'STR' ? parse-str &!
    type is 'COMMENTS' ? parse-alphanumeric &!
    type is 'LAMBDA' ? 'FN'
    type is 'REGEXP' ? parse-regular-expressions &!
    type is 'ARGS' ? parse-args &!
    type is 'WHITESPACE' ||
    type is 'TERMINATOR' ? ' '
    else ? [chunk.0 chunk.0 chunk.0]

process-chunk = fn [code n] {
  type = get-type code
  token = get-token type code
  if token is Vector
    then token ++ [n.line]
    else [type token token n.line]
}

incr-line = match {
  ['TERMINATOR' line] line + 1
  [else] line
}

get-next-index = fn [token]
  { @index (token.2.toString! | (.length))
  @token token }

return-tokens = match {
  [code n] return-tokens code n []
  ['' _ tokens] tokens
  [else] {
    {@index @token} = process-chunk code n | get-next-index
    tokens.push token
    recur
      (code.substr index code.length),
      { @line (incr-line token.0 n.line) },
      tokens
  }
}

filter-whitespace = fn [token]
  not (ignore !! token.0)

tokenize :: String -> Vector
tokenize = fn [code]
  return-tokens code { @index 0 @line 0 } |
    (.filter filter-whitespace)


module.exports = tokenize
