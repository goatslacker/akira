rx = {
  @IDENTIFIER /^([a-zA-Z_$][0-9a-zA-Z_\-]*[\?]?)/
  @KEY /^(@[a-zA-Z_$][0-9a-zA-Z_\-]*[\?]?)/
  @NUM /^(-?([0-9]+[\.e])?[0-9]+,?)+/
  @STR /^('(.*?)')/
  @ARGS /^(&([0-9]+))/
  @LAMBDA /^->/
  @OPERATION /^(<<|<=|>=|>|<|(!|=)==?|\|\||\&\&|!!|\+\+|\+:|::)/
  @TERMINATOR /^\n/
  @REGEXP /^(\/((?![\s=])[^[\/\n\\]*(?:(?:\\[\s\S]|\[[^\]\n\\]*(?:\\[\s\S][^\]\n\\]*)*])[^[\/\n\\]*)*)\/)([imgy]{0,4})(?!\w)/
  @COMMENTS /^(--.*)/
  @WHITESPACE /^ /
}

identifiers = {
  @KEYWORDS [
    'if' 'then' 'else' 'import' 'export' 'try' 'catch' 'none' 'do'
    'let' 'fn' 'raise' 'prototype' 'recur' 'macro' 'cond' 'match' 'interface'
    'Maybe' 'Async' 'class' 'typealias' 'async' 'new' 'await' 'instanceof'
  ]
  @COMPARE ['==' '!=' '>' '>=' '<' '<=' 'is' 'isnt']
  @INHERITANCE ['<<']
  @ACCESSOR_OPERATOR ['!!']
  @LEFT_OPERATORS ['++']
  @RIGHT_OPERATORS ['+:']
  @TYPE_OPERATOR ['::']
  @NOT ['not']
  @LOGIC ['&&' '||']
  @BOOL ['true' 'false']
}

ignore = { @COMMENTS @WHITESPACE }

get-type = fn [a]
  rx | find (-> &0.test a)

extract = fn [key chunk]
  rx !! key | (.exec chunk)

parse-alphanumeric = fn [t chunk (n = 1)]
  extract t chunk | (!! n)

return-identifier = match
  ['KEYWORDS' item] [(| item.toUpperCase) item item]
  [type item] [type item item]

parse-identifier = fn [t chunk]
  item = extract t chunk
  token = identifiers | find (-> &0.indexOf item.1 | (>= 0))
  return-identifier (token || t) item.1

convert-regexp = fn [item]
  RegExp item.2 item.3

parse-regular-expressions = fn []
  & | extract | convert-regexp | (-> ['REGEXP' &0 &0])

parse-args = fn [type chunk]
  token = extract type chunk | (!! 2)
  raw = extract type chunk | (!! 0)
  [type token raw]

special = match
  ['n'] '\n'
  ['r'] '\r'
  ['t'] '\t'
  ['b'] '\b'
  ['f'] '\f'
  [x] x

parse-str = fn [type chunk]
  token = extract type chunk | (!! 2) | fn [str]
    str.replace /\\([a-z])/g (-> special &1)
  raw = extract type chunk | (!! 0)
  [type token raw]

get-token = fn [type chunk]
  cond
    type is 'IDENTIFIER' ||
    type is 'KEY' ||
    type is 'OPERATION' ? & | parse-identifier
    type is 'NUM' ? parse-alphanumeric type chunk 0
    type is 'STR' ? & | parse-str
    type is 'COMMENTS' ? & | parse-alphanumeric
    type is 'LAMBDA' ? 'FN'
    type is 'REGEXP' ? & | parse-regular-expressions
    type is 'ARGS' ? & | parse-args
    type is 'WHITESPACE' ||
    type is 'TERMINATOR' ? ' '
    else ? [chunk.0 chunk.0 chunk.0]

process-chunk = fn [code n]
  type = get-type code
  token = get-token type code
  if token is Vector
    then token ++ [n.line]
    else [type token token n.line]

incr-line = match
  ['TERMINATOR' line] line + 1
  [else] line

get-next-index = fn [token]
  {
    @index (| token.2.toString | (.length))
    @token token
  }

return-tokens = match
  [code n] return-tokens code n []
  ['' _ tokens] tokens
  [else]
    {@index @token} = process-chunk code n | get-next-index
    tokens.push token
    recur (code.substr index code.length) { @line (incr-line token.0 n.line) } tokens

filter-whitespace = fn [token]
  not (ignore !! token.0)

rxindent = /^([ ])+/

tokenize = fn [code]
  lines = code.split '\n'
  tokens = []
  indentstack = []

  dedent-loop = fn [f i]
    if indentstack.length && (| f)
      dedent-num = | indentstack.pop
      tokens.push ['DEDENT' dedent-num ' ' i]
      dedent-loop f i
    else
      tokens.push ['TERMINATOR' ' ' ' ' i]
      none

  dedent = fn [f i]
    (dedent-loop f i) if indentstack.length && (| f)

  lines.for-each fn [line i]
    indentation = if rx.COMMENTS.test line
      then none
      else rxindent.exec line
    indent = if indentation then indentation.0.length else none
    if indent
      if indentstack.length
        last-indent = last indentstack
        cond
          indent > last-indent ?
            indentstack.push indent
            tokens.push ['INDENT' indent ' ' i]
          indent < last-indent ?
            dedent (-> indentstack.length && indent < (last indentstack)) i
          else ? none
      else
        indentstack.push indent
        tokens.push ['INDENT' indent ' ' i]
    else
      (dedent (-> indentstack.length) i) if line != '' && not (rx.COMMENTS.test line)

    tokens.push.apply tokens (
      return-tokens line { @index 0 @line i } | (.filter filterWhitespace)
    )
    tokens.push ['TERMINATOR' ' ' ' ' i]
    line

  dedent (-> indentstack.length) lines.length
  tokens


module.exports = tokenize
