rx = {
  @IDENTIFIER /^([a-zA-Z_$][0-9a-zA-Z_\-]*[\?]?)/
  @KEY /^(@[a-zA-Z_$][0-9a-zA-Z_\-]*)/
  @NUM /^((\d+\.)?\d+)+/
  @STR /^'(.*?)'/
  @LAMBDA /^->/
  @OPERATION /^(<\+|<=|>=|>|<|=>|(!|=)==?|\|\||\&\&|!!|\+\+|\+:)+/
  @TERMINATOR /^\n/
  @REGEX /^(\/((?![\s=])[^[\/\n\\]*(?:(?:\\[\s\S]|\[[^\]\n\\]*(?:\\[\s\S][^\]\n\\]*)*])[^[\/\n\\]*)*)\/)([imgy]{0,4})(?!\w)/
  @COMMENTS /^(--.*)/
  @WHITESPACE /^ /
}

identifiers = {
  @KEYWORDS ['if' 'then' 'else' 'import' 'export' 'try' 'catch' 'none'
    'fn' 'raise' 'prototype' 'recur' 'macro']
  @TYPE ['Function' 'Number' 'String' 'Array' 'Object' 'Null']
  @COMPARE ['==' '!=' '>' '>=' '<' '<=' 'is' 'isnt']
  @LEFT_OPERATORS ['++' '!!']
  @RIGHT_OPERATORS ['=>' '+:']
  @NOT ['not']
  @LOGIC ['and' 'or' '&&' '||']
  @BOOL ['true' 'false']
}

ignore = { @COMMENTS @WHITESPACE }

get-type = fn [a] Object.keys: rx |
  (.filter: (fn [x] rx !! x | (.test: a))) |
  (!! 0)

extract = fn [key chunk] rx !! key | (.exec: chunk)

parse-alphanumeric = fn [t chunk] extract: t chunk | (!! 1)

return-identifier = fn [type item]
  'KEYWORDS' ? [(item.toUpperCase!) item]
  else ? [type item]

parse-identifier = fn [t chunk] {
  item = extract: t chunk
  token = Object.keys: identifiers |
    (.filter: (fn [x] identifiers !! x | (.indexOf: item.2) | (>= 0))) |
    (!! 0)
  return-identifier: token || t item.2
}

parse-regular-expressions = fn [t chunk] {
  item = extract: t chunk
  regexp = RegExp: item.3 item.4
  ['REGEXP' regexp]
}

get-token = fn [t chunk n]
  'IDENTIFIER' ? parse-identifier: t chunk
  'KEY' ? parse-identifier: t chunk
  'NUM' ? parse-alphanumeric: t chunk
  'STR' ? parse-alphanumeric: t chunk
  'OPERATION' ? parse-identifier: t chunk
  'LAMBDA' ? 'FN'
  'REGEX' ? parse-regular-expressions: t chunk
  'COMMENTS' ? parse-alphanumeric: t chunk
  'WHITESPACE' ? ' '
  'TERMINATOR' ? ' '
  else ? [chunk.1 chunk.1]

process-chunk = fn [code n] {
  type = get-type: code
  token = get-token: type code n
  if Array.isArray: token
    then {
      token.push: n.line
      token
    }
    else [type token n.line]
}

get-length = fn [token i]
  'STR' ? i + 2
  else ? i

incr-line = fn [type line]
  'TERMINATOR' ? line + 1
  else ? line

get-next-index = fn [token] {
  @index (token.2.toString! | (.length) | get-length: token.1)
  @token token
}

return-tokens = fn [code n (tokens = [])]
  not code ? tokens
  else ? {
    {@index @token} = process-chunk: code n | get-next-index
    tokens.push: token
    recur
      (code.substr: index code.length),
      { @line (incr-line: token.1 n.line) },
      tokens
  }

filter-whitespace = fn [token] not (ignore !! token.1)

export tokenize = fn [code] return-tokens: code { @index 0 @line 0 } |
  (.filter: filter-whitespace)
